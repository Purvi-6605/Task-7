# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/190qQhmoZu1Ksv0iQhyukykwcgYLx22xQ
"""



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# 1. Load data (adjust filename as needed)
df = pd.read_csv('breast-cancer.csv')  # Kaggle dataset

# Expect features: 'diagnosis' column (M=malignant, B=benign) and others.
# Convert target: M -> 1, B -> 0
df['target'] = df['diagnosis'].map({'M': 1, 'B': 0})

# Drop non-feature columns if present (e.g., 'id', 'diagnosis')
X = df.drop(columns=['id', 'diagnosis', 'target'], errors='ignore')
y = df['target']

# 2. Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# 3. Linear SVM
linear_svm = SVC(kernel='linear', C=1, probability=True)
linear_svm.fit(X_train, y_train)
y_pred_lin = linear_svm.predict(X_test)

print("=== Linear SVM ===")
print("Accuracy:", accuracy_score(y_test, y_pred_lin))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lin))
print("Classification Report:\n", classification_report(y_test, y_pred_lin))

# 4. RBF SVM
rbf_svm = SVC(kernel='rbf', C=1, gamma='scale', probability=True)
rbf_svm.fit(X_train, y_train)
y_pred_rbf = rbf_svm.predict(X_test)

print("\n=== RBF SVM ===")
print("Accuracy:", accuracy_score(y_test, y_pred_rbf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rbf))
print("Classification Report:\n", classification_report(y_test, y_pred_rbf))

# 5. Hyperparameter tuning (RBF)
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.01, 0.001],
    'kernel': ['rbf']
}

grid = GridSearchCV(SVC(probability=True), param_grid, cv=5, verbose=1, n_jobs=-1)
grid.fit(X_train, y_train)

print("\nBest Parameters:", grid.best_params_)
print("Best CV Score:", grid.best_score_)

# Evaluate best on test set
best_svm = grid.best_estimator_
y_pred_best = best_svm.predict(X_test)
print("\n=== Best RBF SVM (Tuned) ===")
print("Accuracy:", accuracy_score(y_test, y_pred_best))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_best))
print("Classification Report:\n", classification_report(y_test, y_pred_best))

# 6. Cross-validation on full data using linear SVM
cv_scores = cross_val_score(linear_svm, X_scaled, y, cv=5)
print("Cross-validation Scores (Linear SVM):", cv_scores)
print("Mean CV Accuracy:", cv_scores.mean())

# 7. Visualization with PCA (2D)
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X_scaled)

# Fit SVM on reduced data (for visualization)
svm_vis = SVC(kernel='rbf', C=grid.best_params_['C'], gamma=grid.best_params_['gamma'])
svm_vis.fit(X_reduced, y)

# Create mesh for plotting
x_min, x_max = X_reduced[:, 0].min() - 1, X_reduced[:, 0].max() + 1
y_min, y_max = X_reduced[:, 1].min() - 1, X_reduced[:, 1].max() + 1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),
                     np.linspace(y_min, y_max, 300))

Z = svm_vis.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.2, cmap=plt.cm.coolwarm)
plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=plt.cm.coolwarm,
            s=30, edgecolors='k')
plt.title("SVM Decision Boundary (PCA-reduced Data)")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.show()